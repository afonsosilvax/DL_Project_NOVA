## ⚠️ Some issues that we were facing with hyperband

### 🔹 1.1 Model Not Built Before Loading Weights
- As seen in your error, **Hyperband may try to reload weights into an unbuilt model**.
- **Fix**: Ensure `model.build(input_shape=...)` is called **before loading weights**.

### 🔹 1.2 Unstable Training with Large Search Spaces
- Hyperband **aggressively allocates resources** to promising trials while **terminating weaker ones early**.
- If your search space is **too wide**, the tuner might:
  - Explore **too many weak configurations early**.
  - **Miss better hyperparameter sets** that require more training.

## 🔹 Why Random Search with Early Stopping Can Be Better than Hyperband

### 🚀 Less Risk of Discarding Good Trials Too Early
- Hyperband aggressively **stops trials early** based on initial performance.
- If your model has a **slow convergence rate**, Hyperband might **kill a good configuration too soon**.
- **Random Search + Early Stopping ensures that each trial gets a fair chance** before stopping.

### 🎯 More Flexible Search Space
- Hyperband relies on **fixed brackets and rounds**, while **Random Search explores freely**.
- If your model has **some rare but highly effective hyperparameter sets**, Random Search has **higher chances of finding them**.

### 📊 Better for Noisy Datasets
- If your dataset is **noisy** or **imbalanced**, early stopping with patience can **prevent overfitting without discarding trials too soon**.
- Hyperband might **overreact to initial fluctuations in validation loss**.

### 🔄 More Stable and Reproducible
- Hyperband's **early termination strategy makes it less deterministic**.
- **Random Search + Callbacks provides more control over when training stops**.
